#  LangChain: Fundamentos para la Construcci贸n de Aplicaciones con LLM

Este repositorio contiene una serie de cuadernos Jupyter que exploran los **bloques de construcci贸n fundamentales** para crear aplicaciones robustas y modulares con Large Language Models (**LLMs**) utilizando la librer铆a **LangChain** y la API de **OpenAI**.

##  Objetivos del Proyecto

El objetivo principal es pasar de las llamadas directas a la API de OpenAI a un enfoque estructurado y modular, aprendiendo a gestionar el **contexto** (Memoria), el **flujo** (Cadenas) y la **estructura de datos** (Parsers).

---

## 锔 Estructura del Repositorio y Conceptos Clave

| Cuaderno | Conceptos Cubiertos | Enfoque Principal |
| :--- | :--- | :--- |
| `L1-Model_prompt_parser.ipynb` | Modelos, Prompts y Parsers de Salida | **Estructuraci贸n de la Entrada y Salida (I/O).** |
| `L2-Memory.ipynb` | Tipos de Memoria | **Persistencia del Contexto Conversacional.** |
| `L3-Chains.ipynb` | Tipos de Cadenas (*Chains*) | **Automatizaci贸n de Flujos de Trabajo Inteligentes.** |

---

## 1.  M贸dulo de I/O: Modelos, Prompts y Parsers (L1)

Este m贸dulo cubre la preparaci贸n de la entrada para el LLM y la interpretaci贸n de su salida.

| Componente | Funci贸n T茅cnica | Prop贸sito Sencillo |
| :--- | :--- | :--- |
| **Prompts** | Clase `ChatPromptTemplate`. Define plantillas con *placeholders* (`{variable}`) para crear instrucciones reutilizables. | Separar la **instrucci贸n fija** (la tarea) de las **entradas variables** (el texto del usuario, el estilo). |
| **Output Parsers** | Clases `ResponseSchema` y `StructuredOutputParser`. Fuerza al LLM a generar una salida en formato **JSON** y la convierte en un objeto usable de Python (`dict`). | Tomar la respuesta del robot (que es texto) y convertirla en una **estructura de datos** f谩cil de manipular. |
| **Modelos (LLMs)** | Clase `ChatOpenAI`. Es la interfaz est谩ndar de LangChain para interactuar con los modelos de chat. | El "control remoto" para enviar y recibir datos del robot inteligente. |

---

## 2.  M贸dulo de Memoria (L2)

Este m贸dulo se enfoca en dotar a los *chatbots* de **contexto**, resolviendo el problema de que los LLMs son inherentemente "sin estado" (*stateless*).

| Tipo de Memoria | Funci贸n Principal | Control de Longitud |
| :--- | :--- | :--- |
| **`ConversationBufferMemory`** | Almacena el **historial completo**. | **Ninguno.** El historial crece indefinidamente. |
| **`ConversationTokenBufferMemory`** | Limita el historial seg煤n el **n煤mero total de *tokens*** consumidos. | **Estricto por Costo/Tama帽o.** Recorta mensajes antiguos para ajustarse al l铆mite. |
| **`ConversationSummaryBufferMemory`** | **Resume** las partes m谩s antiguas de la conversaci贸n (usando el LLM) y mantiene expl铆citas las interacciones recientes. | **Inteligente.** Mantiene el contexto relevante y el resumen informativo. |

---

## 3. 锔 M贸dulo de Cadenas (*Chains*) (L3)

El m贸dulo de Cadenas cubre la automatizaci贸n de flujos de trabajo al permitir enlazar m煤ltiples operaciones con LLMs. 

| Tipo de Cadena | Funci贸n Principal | Control de Flujo |
| :--- | :--- | :--- |
| **`LLMChain`** | La cadena m谩s b谩sica. Combina un LLM con una plantilla de prompt para una **tarea 煤nica**. | Directo. |
| **`SequentialChain`** | Permite **flujos de trabajo complejos** donde se combinan subcadenas con m煤ltiples entradas y salidas. | Secuencial (M煤ltiples entradas/salidas). |
| **`RouterChain`** | Utiliza un **Agente LLM** para analizar la entrada y **decidir a qu茅 subcadena especializada** debe enrutar la petici贸n. | **Decisi贸n Inteligente.** (Ej., enrutar preguntas de F铆sica a la cadena de F铆sica). |

## 4.  M贸dulo de QA sobre Documentos (RAG) (L4)

Este m贸dulo es fundamental para construir sistemas de **Preguntas y Respuestas sobre datos propios** (RAG: *Retrieval-Augmented Generation*), superando el l铆mite de contexto de los LLMs.

* **Embeddings:** Se introducen las **representaciones num茅ricas** (vectores) de texto que capturan el significado sem谩ntico.
* **Vector Stores:** Se utiliza la base de datos vectorial (`DocArrayInMemorySearch`) para **indexar** y **almacenar** los *embeddings* de los documentos.
* **Recuperaci贸n:** La cadena **`RetrievalQA`** combina el LLM con el **Recuperador** (`Retriever`) para buscar los fragmentos de documentos m谩s relevantes a la consulta y solo pasar ese contexto al modelo.
* **Tipos de Cadena QA:** Se exploran estrategias para manejar grandes vol煤menes de documentos, como **`stuff`**, **`map_reduce`**, y **`refine`**.

---

## 5.  M贸dulo de Evaluaci贸n (L5)

Este m贸dulo se enfoca en la calidad y el mantenimiento de las aplicaciones de LLM.

* **Debugging (Depuraci贸n):** Se utiliza la opci贸n **`verbose=True`** en las cadenas para inspeccionar el flujo de ejecuci贸n (el *prompt* enviado y los documentos recuperados) y diagnosticar problemas (ej. la recuperaci贸n fall贸 o la generaci贸n fue incorrecta).
* **Generaci贸n de Ejemplos:** Se muestra c贸mo utilizar un LLM para crear autom谩ticamente conjuntos de datos de evaluaci贸n (pares de **pregunta**, **respuesta ideal** y **contexto**).
* **Evaluaci贸n Asistida por LLM:** Se usa un **segundo LLM como juez** para calificar autom谩ticamente la respuesta generada por la cadena de prueba contra la respuesta ideal, midiendo la **Correcci贸n** y la **Fidelidad**.

---
## 6.  M贸dulo de Agentes (*Agents*) (L6)

Este m贸dulo es la c煤spide de la construcci贸n con LangChain, presentando el LLM no como una herramienta de respuesta, sino como un **Motor de Razonamiento** capaz de decidir qu茅 acciones tomar y qu茅 herramientas utilizar para resolver tareas complejas de forma din谩mica.

| Componente | Funci贸n Principal | Rol en el Flujo de Trabajo |
| :--- | :--- | :--- |
| **Agente (LLM)** | Act煤a como el controlador principal y el motor de toma de decisiones. | **Piensa** (*Thought*), **act煤a** (*Action*), y **observa** (*Observation*). |
| **Herramientas (*Tools*)** | Interfaces espec铆ficas para interactuar con datos externos (Web, bases de datos, c贸digo). | Proporcionan informaci贸n fuera del conocimiento interno del LLM. |
| **Tipo ReAct** | **`CHAT_ZERO_SHOT_REACT_DESCRIPTION`** | Es la estrategia de *prompting* que obliga al Agente a razonar antes de actuar. |
| **Herramientas Personalizadas** | Funciones de Python decoradas con `@tool`. | Permite conectar el Agente a API, bases de datos o c贸digo local. |

### Flujo de Razonamiento (Ciclo ReAct)

El Agente resuelve las consultas iterativamente a trav茅s de un ciclo de tres pasos:

1.  **Pensamiento (`Thought`):** El Agente determina la mejor estrategia o la informaci贸n que necesita.
2.  **Acci贸n (`Action`):** El Agente selecciona la herramienta m谩s adecuada (ej. DuckDuckGo, Wikipedia o una funci贸n personalizada).
3.  **Observaci贸n (`Observation`):** El resultado de la herramienta se devuelve al Agente, que lo utiliza como nuevo contexto para su siguiente pensamiento.
